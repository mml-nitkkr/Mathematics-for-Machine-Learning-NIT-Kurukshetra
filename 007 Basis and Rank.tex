\documentclass{article}

\usepackage{fancyhdr}
\cfoot{
\vspace{1mm}\hspace{3cm}
\includegraphics[width=0.2\textwidth]{CC-BY-NC-SA.pdf}}

\renewcommand{\headrulewidth}{0pt}
\renewcommand{\footrulewidth}{0pt}
\setlength\headheight{80.0pt}
\addtolength{\textheight}{-80.0pt}

\usepackage[margin = 3cm, footskip = 30pt]{geometry}
\usepackage{amsmath}
\usepackage{blkarray}
\usepackage[table]{xcolor}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{enumerate}

\newcommand\bg{\cellcolor{gray!70}}
\newcommand{\suchthat}{\;\ifnum\currentgrouptype=16 \middle\fi|\;}% check https://tex.stackexchange.com/questions/45713/creating-a-large-such-that-symbol

\usepackage{stackengine,graphicx}
\def\stacktype{L}
\def\useanchorwidth{T}
\newcommand\strike[1]{\stackon[3.3pt]{#1}{\rule{4.5ex}{1pt}}}
\newcommand\vstrike[1]{\stackon[0pt]{#1}{\smash{\rule[-3pt]{1pt}{2.9ex}}}}

\usepackage{tikz}
\usetikzlibrary{shapes.geometric, arrows,positioning,automata}


\makeatletter
\renewcommand*\env@matrix[1][*\c@MaxMatrixCols c]{
  \hskip -\arraycolsep
  \let\@ifnextchar\new@ifnextchar
  \array{#1}}
\makeatother

\title{Basis and Rank (Part 007)}
\author{Dr. Kapil \\kapil$@$nitkkr$\cdot$ac$\cdot$in\\Department of Computer Application\\NIT Kurukshetra}
\date{\today}
\begin{document}
\maketitle
\thispagestyle{fancy}
In the last part we have discussed linear dependence and linear independence of the set of vectors. And we found a few ways to identify linearly dependent and linearly independent vectors from a given set of vectors. So, now we have a few questions-
\begin{enumerate}
    \item If I start with a set of vectors and add all possible linear combinations of these vectors to the set of vectors, will it be a vector space? \\
    We know from the previous part that to be a subspace we just need to prove that the set of vectors under consideration must be closed for linear combination. Therefore, yes we will get a subspace after add all possible linear combinations.
    \item Will it fill the entire vector space or something smaller?\\
    Possibly this also, we can answer because it maybe a subspace or the entire vector space depending on the case.
    \item To say something smaller, I must be able to quantify it, so can we quantify the largeness of the vector space (if at all it makes)?
    \item Above questions comes into mind when we move from a smaller set to a bigger set of vectors, what if we further reduce the number of vectors in the set of vectors? Is it okay? Maybe we can say it more concretely by removing only linearly dependent vectors because linearly dependent vectors can be made again by some linear combination of other vectors.
    \item Where or when will reducing the vectors from the set of vectors stop?
    \item Will that be some unique set?
    \item Will they still be able to generate the same big set of vectors as generated by initial set of vectors?
\end{enumerate}
Possibly, from the discussion that we did in last part, we can answer first two questions.
\begin{enumerate}
    \item  In order to attempt first question, we know from the previous part that to be a subspace we just need to prove that the set of vectors under consideration must be closed for linear combination. Therefore, yes we will get a subspace after adding all possible linear combinations of the vectors in the set.
    \item We can answer the second question as well because we know the definition of subspace but it maybe the entire vector space depending on the case.
\end{enumerate}
Now, we will try to answer all such questions but before that let us learn some vocabulary that will be needed to answer these questions.\par

Consider a vector space $V=(\mathcal{V},+,\cdot)$ and set of vectors $\mathcal{A}=\{ {x_1},\ldots ,{x_k}\} \subseteq \mathcal{V}$. if every vector $\vec{v} \in \mathcal{V} $  can be expressed as some linear combination of vectors in $\mathcal{A}$, then $\mathcal{A}$ is known as \textit{generating set} of $V$. \\

The set of all possible linear combination of vector in $\mathcal{A}$ is called \textit{span of} $\mathcal{A}$ or span($\mathcal{A}$). If $\mathcal{A}$ spans the entire vector space $V$, in other words if the linear combinations of the vectors in $\mathcal{A}$ can generate all the vectors in $\mathcal{V}$, then we write $V=span(\mathcal{A})$ or $V=span(x_1,\ldots,x_k)$.\\

Let $V=(\mathcal{V},+,\cdot),~~\mathcal{A}\subseteq\mathcal{V}$ and $\mathcal{A}$ is generating set of $V$ then, $\mathcal{A}$ is called \textit{minimal generating set} if $\nexists X \subseteq \mathcal{A} \suchthat V=span(X)$. \\

Let $V=(\mathcal{V},+,\cdot),~~\mathcal{A}\subseteq\mathcal{V}$ and each vector in $\mathcal{A}$ is linearly independent of others then, $\mathcal{A}$ is called \textit{maximally linearly independent set} if $\nexists X \suchthat (\mathcal{V} \supseteq X \supseteq \mathcal{A})$ and vectors in $X$ are linearly independent. \\

\section{Basis}
Every linearly independent generating set of $V$ is minimal and is known as \textit{Basis} of $V$.\\

Let $V=(\mathcal{V},+, .)$ be a vector space and $\mathcal{B}\subseteq\mathcal{V},~~ \mathcal{B} \ne \phi$.\\
Then the following statements are equivalent -
\begin{enumerate}[i]
    \item $\mathcal{B}$ is basis of $V$
    \item $\mathcal{B}$ is minimal generating set of $V$
    \item $\mathcal{B}$ is maximally linearly independent set of vectors in $V$
    \item $\forall \vec{v}\in\mathcal{V}$ can be expressed as linear combinations of vectors in $\mathcal{B}$ uniquely.\\
    i.e. $B\vec{y}$ = $\Vec{v}$, where $B$ is matrix whose columns are made up of vectors in $\mathcal{B}$, has unique solution.
\end{enumerate}

\subsection{Example}
\begin{itemize}
    \item Let \(V =(\mathcal{V},+,\cdot)\) be a vector space and \( \mathcal{V}= \left\{ 
    \begin{pmatrix}
    x\\2x
    \end{pmatrix} \suchthat x \in \mathbb{R}
    \right\}\). Now, consider \(A_1 = \left\{
\begin{pmatrix}
1\\2
\end{pmatrix}
,
\begin{pmatrix}
2\\4
\end{pmatrix}
,\begin{pmatrix}
3\\6
\end{pmatrix}\right\}\) or \({A_2} = \left\{
\begin{pmatrix}
1\\2
\end{pmatrix},
\begin{pmatrix}
0.5\\1
\end{pmatrix}
,\begin{pmatrix}
3\\6
\end{pmatrix}\right\}\) or \({A_3} = \left\{
\begin{pmatrix}
0\\0
\end{pmatrix},
\begin{pmatrix}
1\\2
\end{pmatrix}\right\}\). I think you will acknowledge that they all are generating sets of $V$. But notice all of these ${A_1},{A_2},{A_3}$ are linearly dependent sets of vectors. Hence, they can not be basis.\\

I hope you have got \(A= \left\{\vec{b}=
\begin{pmatrix}
1\\2
\end{pmatrix}
\right\}\) can also be a generating set having only one item. And it has to be linearly independent set as \(c\vec{v}= \begin{pmatrix} 0 \\ 0\end{pmatrix} \) is possible only if $c=0$. Therefore , \(B=\left\{\begin{pmatrix} 1 \\ 2 \end{pmatrix} \right\}\) is also a basis of $V$. You can also notice that for any $\vec{v} \in \mathcal{V}$, the matrix equation $c \vec{b} = \vec{v}$ has unique solution. But let me remind you that this is not the only basis. In fact, any of 
\(B_1 = \left \{ \begin{pmatrix} 0.5\\1 \end{pmatrix} \right\}\) 
or \( B_2 = \left\{\begin{pmatrix}3\\6\end{pmatrix}\right\}\)
or \(B_3 = \left\{\begin{pmatrix}2.5\\5\end{pmatrix}\right\}\) can be basis of $V$.
In other words, all of them are basis and can span entire $V$ independently i.e.-
\begin{align*}
    V=span({B_1})\\
     =span({B_2})\\
     =span({B_3})\\
\end{align*}
\item Consider following set of vectors-
\[\mathcal{A}_1=
 \left\{\vec{v}_1=
\begin{pmatrix}
0\\1
\end{pmatrix}
,\vec{v}_2=
\begin{pmatrix}
1\\0
\end{pmatrix}
,\vec{v}_3=\begin{pmatrix}
2\\3
\end{pmatrix}
,\vec{v}_4=\begin{pmatrix}
3\\2
\end{pmatrix}
,\vec{v}_5=\begin{pmatrix}
4\\5
\end{pmatrix}
,\vec{v}_6=\begin{pmatrix}
x\\y
\end{pmatrix}
\suchthat  x,y \in \mathbb{R}
\right\}\]

You can notice that $\Vec{v_1}$ and $\Vec{v_2}$ can generate any vector in $V=(\mathbb{R}^2,+,\cdot)$ i.e. \[c_1\Vec{v}_1+c_2.\Vec{v}_2=
\begin{pmatrix} c_1\\c_2\end{pmatrix} \forall c_1, c_2 \in \mathbb{R}.\] 
and both the vectors $\vec{v}_1$ and $\vec{v}_2$ are linearly independent.
\(\therefore B_1 = \left\{
\begin{pmatrix}
1\\0
\end{pmatrix}
,
\begin{pmatrix}
0\\1
\end{pmatrix}
\right\} \) is a basis of $V$. But, 
\(B_2 = \left\{
\begin{pmatrix}
2\\3
\end{pmatrix},
\begin{pmatrix}
1\\0
\end{pmatrix}
\right\}\)
or 
\(B_3 = \left\{
\begin{pmatrix}
2\\3
\end{pmatrix},
\begin{pmatrix}
4\\5
\end{pmatrix}\right\}\) can also generate any \(\begin{pmatrix}
x\\y
\end{pmatrix} \in V\) because it means finding right $\alpha$, $\beta \in \mathbb{R}$, such that- \\
\[\begin{pmatrix}
2\\3
\end{pmatrix}\alpha
+ \begin{pmatrix}
4\\5
\end{pmatrix}\beta = 
\begin{pmatrix}
2\alpha + 4\beta\\
3\alpha + 5\beta    
\end{pmatrix}
=
\begin{pmatrix}
x\\y
\end{pmatrix}\]
which is essentially a system of linear equations with matrix equivalent $A\Vec{x} = \Vec{b}$ , Here $\Vec{x}=\begin{pmatrix}
\alpha\\\beta
\end{pmatrix}$ and $\Vec{b}=\begin{pmatrix}
x\\y
\end{pmatrix}$. 
Since $A$ is not singular or determinant of $A =10-12=-2\ne0$ therefore, it will always have unique solution. Basically, $V$ here is exactly $\mathbb{R}^2$.\\

\item Now, let us take an example in $\mathbb{R}^3$ to understand the idea clearly. Consider a set of vectors \(\left\{
\begin{pmatrix}
1\\0\\0
\end{pmatrix},
\begin{pmatrix}
0\\1\\0
\end{pmatrix},
\begin{pmatrix}
0\\0\\1
\end{pmatrix}
\right\}\). These are linearly independent vectors i.e. linear combination of these vectors can generate zero if and only if all the scalars multiplied to the respective vectors are zero. In other words, if  $A\vec{c}=\vec{0} \iff c= \Vec{0}$ or $A\vec{c} =\vec{0}$ has unique solution.\\
\( A=\begin{pmatrix}
1 & 0 & 0\\
0 & 1 & 0\\
0 & 0 & 1
\end{pmatrix}, \vec{c}=
\begin{pmatrix}
c_1\\
c_2\\
c_3
\end{pmatrix}\). And further you know that you can make any arbitrary point in the three dimensional (3D) space by using these three vectors i.e.
\(\begin{pmatrix}
x\\y\\z
\end{pmatrix}=x
\begin{pmatrix}
1\\0\\0
\end{pmatrix} + y\begin{pmatrix}
0\\1\\0
\end{pmatrix} + z\begin{pmatrix}
0\\0\\1
\end{pmatrix}\). Thus, we can say columns of $A$ spans $\mathbb{R}^3$. Hence, columns of $A$ forms a basis of $\mathbb{R}^3$ .

\item Let us try to find if the following vectors forms a basis-\\
\(\begin{pmatrix}
4\\2\\6
\end{pmatrix},
\begin{pmatrix}
3\\6\\2
\end{pmatrix},\begin{pmatrix}
5\\7\\5
\end{pmatrix},\begin{pmatrix}
1\\5\\-1
\end{pmatrix}\)
To check we have to find if all the vectors are linearly independent of each other or not. i.e\\
\(\begin{bmatrix}
4 & 3 & 5 & 1\\
2 & 6 & 7 & 5\\
6 & 2 & 5 & -1
\end{bmatrix}
\begin{bmatrix}
x_1\\
x_2\\
x_3\\
x_4
\end{bmatrix}=
\begin{bmatrix}
0\\
0\\
0
\end{bmatrix}\)
should have unique solution. Clearly, we cannot find determinant here as the matrix is not square matrix. So, here we will try to find row echelon form then the columns corresponding to pivot elements can generate all the vectors that do not have pivots and hence can form a basis.\par

For this question only two columns will be found. Hence, currently it cannot work as basis. But here we have found, how to identify the basis from a set of vectors.
 
Find the right linear combination of pivot columns that can make non-pivot columns.\\
 
 \textbf{Notice} that the third vector, $\Vec{v}_3=\Vec{v}_2+\frac{1}{2}\Vec{v}_1$, and that fourth vector, $\Vec{v_4}=\Vec{v_3}-\Vec{v_1}$. I made it like that, you should notice the connection between the columns and rows. As you did row operations to find pivot column.\\
 
 
 \textbf{ARGUE} Maximum number of pivots you can find in any $m\times n$ matrix is $min(m,n)$. Why? (\textit{Hint:} Try to take a matrix of $2\times 3$ and a $3\times 2$ order and apply Gauss elimination. Do it few more times while keeping the question in mind. You must be able to answer m or if not please email us: mml.nitkkr@gmail.com )\\
 
 There could be another way to find what vectors can be written as linear combinations of other vectors. And what is the right linear combination that can make the linearly dependent vectors (\textit{Hint:} Apply Gauss elimination on the below matrix. \(\begin{bmatrix}
4 & 2 & 6\\
3 & 6 & 2\\
5 & 7 & 5\\
1 & 5 & -1
\end{bmatrix}\). Notice that this matrix is transpose of previous matrix.)
\end{itemize}
There are some questions for thought-
\begin{itemize}
    \item Does vector space spanned by rows of row echelon form of $A$ is same as that of vector space spanned by rows of $A$?
    \item Does vector space spanned by columns of row echelon form of $A$ is same as that of vector space spanned by columns of $A$?
    \item Does vector space spanned by rows of row echelon form of $A$ is same as that of vector space spanned by columns of row echelon form of $A^T$?
\end{itemize}
Answer to the above questions lie in the fact that Gauss elimination replaces any row vector by some linear combination of row thereby never going beyond the space spanned by original vectors. But there is no such surety with vector space spanned by original column vectors of $A$. 

\section{Dimension}

Every vector space $V$ (except where $\mathcal{V}=\{\vec{0}\}$) possess at least a basis $\mathcal{B}$. In general, each vector space has many bases. But number of vectors in all the bases is same. This number is known as \textit{dimension of the vector space}. This number help us quantifying the largeness of the subspace. This is again same as that of number of pivot elements in row echelon form.\\

If $U$ is some subspace of $V$, then $dim(U)\leq dim(V)$. But $dim(U)$ is same as that of $dim(V)$ is possible if and only if $U=V$. You should notice that dimension of vector space does not relate with the number of components in each vector of the vector space. For example, the vector space $V = span \left (\left \{\begin{bmatrix} 1\\0 \end{bmatrix} \right\} \right )$ is a one dimensional vector space.

\section{Rank}
\end{document}
